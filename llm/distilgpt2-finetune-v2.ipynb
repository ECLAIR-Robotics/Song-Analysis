{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c78a7fb-edce-4a67-917a-f0099a9303d8",
   "metadata": {},
   "source": [
    "# distilGPT2 Fine-Tuning v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe50c734-113a-416e-a590-b8a5f6cbb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "ver = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b86845-b402-41ed-9572-764d6a99b09c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94eee7e-3c43-43e4-bc11-58efce82e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.last.fm/music/metallica/_/st.%2banger</td>\n",
       "      <td>St. Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>727a2529-7ee8-4860-aef6-7959884895cb</td>\n",
       "      <td>3fOc9x06lKJBhz435mInlH</td>\n",
       "      <td>metal</td>\n",
       "      <td>Saint Anger 'round my neck\\nSaint Anger 'round...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.last.fm/music/m.i.a./_/bamboo%2bbanga</td>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>['aggressive', 'fun', 'sexy', 'energetic']</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>99dd2c8c-e7c1-413e-8ea4-4497a00ffa18</td>\n",
       "      <td>6tqFC1DIOphJkCwrjVzPmg</td>\n",
       "      <td>hip-hop</td>\n",
       "      <td>Road runner, road runner\\nGoing hundred mile p...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.last.fm/music/drowning%2bpool/_/st...</td>\n",
       "      <td>Step Up</td>\n",
       "      <td>Drowning Pool</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>9</td>\n",
       "      <td>2.971389</td>\n",
       "      <td>5.537500</td>\n",
       "      <td>4.726389</td>\n",
       "      <td>49e7b4d2-3772-4301-ba25-3cc46ceb342e</td>\n",
       "      <td>4Q1w4Ryyi8KNxxaFlOQClK</td>\n",
       "      <td>metal</td>\n",
       "      <td>Come!\\n\\nIf our own lives aren’t directly affe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>https://www.last.fm/music/kanye%2bwest/_/feedback</td>\n",
       "      <td>Feedback</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49fT6owWuknekShh9utsjv</td>\n",
       "      <td>hip-hop</td>\n",
       "      <td>Ayy, y'all heard about the good news?\\nY'all s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>https://www.last.fm/music/deftones/_/7%2bwords</td>\n",
       "      <td>7 Words</td>\n",
       "      <td>Deftones</td>\n",
       "      <td>['aggressive', 'angry']</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807121</td>\n",
       "      <td>5.473939</td>\n",
       "      <td>4.729091</td>\n",
       "      <td>1a826083-5585-445f-a708-415dc90aa050</td>\n",
       "      <td>6DoXuH326aAYEN8CnlLmhP</td>\n",
       "      <td>nu metal</td>\n",
       "      <td>I'll never be the same, breaking decency\\nDon'...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16792</th>\n",
       "      <td>229432</td>\n",
       "      <td>https://www.last.fm/music/noblegases/_/xenon</td>\n",
       "      <td>Xenon</td>\n",
       "      <td>NobleGases</td>\n",
       "      <td>['noble']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.160000</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>6.130000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1AePjgLLtzF0abbfcgYdLI</td>\n",
       "      <td>chill</td>\n",
       "      <td>You're floating out astray\\nThis cold and life...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16793</th>\n",
       "      <td>229435</td>\n",
       "      <td>https://www.last.fm/music/kurt%2bvile/_/wild%2...</td>\n",
       "      <td>Wild Imagination</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.925000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>6.190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1Gn0oYQiQHp7KF4DcR2g4t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm looking at you\\nBut It's only a picture so...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16794</th>\n",
       "      <td>229436</td>\n",
       "      <td>https://www.last.fm/music/portugal.%2bthe%2bma...</td>\n",
       "      <td>Oh Lord</td>\n",
       "      <td>Portugal. The Man</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>7ea228f9-16d0-474d-8c51-5a1a9810ddde</td>\n",
       "      <td>6YG8cjbrjhDhlYMiQnibUD</td>\n",
       "      <td>indie</td>\n",
       "      <td>\\n\\n\\nWhere do I fit in\\nI am waiting here for...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>229443</td>\n",
       "      <td>https://www.last.fm/music/porcelain%2band%2bth...</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Porcelain and The Tramps</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>3</td>\n",
       "      <td>6.613333</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>5.773333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>industrial</td>\n",
       "      <td>Wish I were transparent\\nYou could see right t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>229473</td>\n",
       "      <td>https://www.last.fm/music/daniel%2blanois/_/lo...</td>\n",
       "      <td>Lovechild</td>\n",
       "      <td>Daniel Lanois</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.685000</td>\n",
       "      <td>4.405000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c</td>\n",
       "      <td>4fVObxldDzxxRD6a5Eth9s</td>\n",
       "      <td>indie</td>\n",
       "      <td>I CAUGHT HER STARING, A PSYCHEDELIC DANCER,\\nG...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16797 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         lastfm_url  \\\n",
       "0               1  https://www.last.fm/music/metallica/_/st.%2banger   \n",
       "1               3  https://www.last.fm/music/m.i.a./_/bamboo%2bbanga   \n",
       "2               5  https://www.last.fm/music/drowning%2bpool/_/st...   \n",
       "3              11  https://www.last.fm/music/kanye%2bwest/_/feedback   \n",
       "4              13     https://www.last.fm/music/deftones/_/7%2bwords   \n",
       "...           ...                                                ...   \n",
       "16792      229432       https://www.last.fm/music/noblegases/_/xenon   \n",
       "16793      229435  https://www.last.fm/music/kurt%2bvile/_/wild%2...   \n",
       "16794      229436  https://www.last.fm/music/portugal.%2bthe%2bma...   \n",
       "16795      229443  https://www.last.fm/music/porcelain%2band%2bth...   \n",
       "16796      229473  https://www.last.fm/music/daniel%2blanois/_/lo...   \n",
       "\n",
       "                  track                    artist  \\\n",
       "0             St. Anger                 Metallica   \n",
       "1          Bamboo Banga                    M.I.A.   \n",
       "2               Step Up             Drowning Pool   \n",
       "3              Feedback                Kanye West   \n",
       "4               7 Words                  Deftones   \n",
       "...                 ...                       ...   \n",
       "16792             Xenon                NobleGases   \n",
       "16793  Wild Imagination                 Kurt Vile   \n",
       "16794           Oh Lord         Portugal. The Man   \n",
       "16795       Transparent  Porcelain and The Tramps   \n",
       "16796         Lovechild             Daniel Lanois   \n",
       "\n",
       "                                            seeds  number_of_emotion_tags  \\\n",
       "0                                  ['aggressive']                       8   \n",
       "1      ['aggressive', 'fun', 'sexy', 'energetic']                      13   \n",
       "2                                  ['aggressive']                       9   \n",
       "3                                  ['aggressive']                       1   \n",
       "4                         ['aggressive', 'angry']                      10   \n",
       "...                                           ...                     ...   \n",
       "16792                                   ['noble']                       2   \n",
       "16793                             ['transparent']                       2   \n",
       "16794                             ['transparent']                       1   \n",
       "16795                             ['transparent']                       3   \n",
       "16796                             ['transparent']                       2   \n",
       "\n",
       "       valence_tags  arousal_tags  dominance_tags  \\\n",
       "0          3.710000      5.833000        5.427250   \n",
       "1          6.555071      5.537214        5.691357   \n",
       "2          2.971389      5.537500        4.726389   \n",
       "3          3.080000      5.870000        5.490000   \n",
       "4          3.807121      5.473939        4.729091   \n",
       "...             ...           ...             ...   \n",
       "16792      6.160000      3.695000        6.130000   \n",
       "16793      6.925000      4.975000        6.190000   \n",
       "16794      5.370000      3.450000        5.330000   \n",
       "16795      6.613333      4.633333        5.773333   \n",
       "16796      6.685000      4.405000        5.625000   \n",
       "\n",
       "                                       mbid              spotify_id  \\\n",
       "0      727a2529-7ee8-4860-aef6-7959884895cb  3fOc9x06lKJBhz435mInlH   \n",
       "1      99dd2c8c-e7c1-413e-8ea4-4497a00ffa18  6tqFC1DIOphJkCwrjVzPmg   \n",
       "2      49e7b4d2-3772-4301-ba25-3cc46ceb342e  4Q1w4Ryyi8KNxxaFlOQClK   \n",
       "3                                       NaN  49fT6owWuknekShh9utsjv   \n",
       "4      1a826083-5585-445f-a708-415dc90aa050  6DoXuH326aAYEN8CnlLmhP   \n",
       "...                                     ...                     ...   \n",
       "16792                                   NaN  1AePjgLLtzF0abbfcgYdLI   \n",
       "16793                                   NaN  1Gn0oYQiQHp7KF4DcR2g4t   \n",
       "16794  7ea228f9-16d0-474d-8c51-5a1a9810ddde  6YG8cjbrjhDhlYMiQnibUD   \n",
       "16795                                   NaN                     NaN   \n",
       "16796  16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c  4fVObxldDzxxRD6a5Eth9s   \n",
       "\n",
       "            genre                                              Lyric language  \n",
       "0           metal  Saint Anger 'round my neck\\nSaint Anger 'round...       en  \n",
       "1         hip-hop  Road runner, road runner\\nGoing hundred mile p...       en  \n",
       "2           metal  Come!\\n\\nIf our own lives aren’t directly affe...       en  \n",
       "3         hip-hop  Ayy, y'all heard about the good news?\\nY'all s...       en  \n",
       "4        nu metal  I'll never be the same, breaking decency\\nDon'...       en  \n",
       "...           ...                                                ...      ...  \n",
       "16792       chill  You're floating out astray\\nThis cold and life...       en  \n",
       "16793         NaN  I'm looking at you\\nBut It's only a picture so...       en  \n",
       "16794       indie  \\n\\n\\nWhere do I fit in\\nI am waiting here for...       en  \n",
       "16795  industrial  Wish I were transparent\\nYou could see right t...       en  \n",
       "16796       indie  I CAUGHT HER STARING, A PSYCHEDELIC DANCER,\\nG...       en  \n",
       "\n",
       "[16797 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../out.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "831ecb5f-381e-4219-bc64-911192838f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_tags = [\"melancholy\", \"sad\", \"bittersweet\", \"sentimental\", \"cynical\", \"nostalgic\",\n",
    "            \"lonely\", 'regretful',\"sardonic\", \"poignant\", \"gloomy\", \"brooding\", \"yearning\",\n",
    "           \"negative\", \"apocalyptic\", \"tragic\", \"bleak\", \"somber\", \"desperate\", \"grim\", \"detached\"\n",
    "           \"fractured\", \"anxious\", \"nihilistic\", \"angst-ridden\", \"nervous\", \"weary\", \"distraught\", \n",
    "           \"self-conscious\", \"funereal\", \"suffocating\", \"elegiac\", \"cold\", \"dark\", 'wistful']\n",
    "happy_tags = [\"happy\", 'light',\"comic\", 'campy', \"fun\", \"sweet\", \"cheerful\", \"warm\", \"positive\", \"silly\", \"playful\", \"optimistic\",\n",
    "            \"bright\", \"humorous\", \"lively\", \"exciting\", \"euphoric\", \"summery\", 'uplifting'\n",
    "             \"joyous\", \"triumphant\", \"carefree\", \"exuberant\", \"ecstatic\", \"sparkling\", \"celebratory\", \n",
    "             \"perky\", \"boisterous\", \"swaggering\", \"sugary\", \"amiable\", \"good-natured\", \"gleeful\",\n",
    "             \"agreeable\", \"jovial\", \"giddy\", \"ebullient\", \"effervescent\", 'whimsical']\n",
    "energetic_tags = [\"epic\", \"intense\", \"powerful\", \"energetic\", \"driving\", \"rousing\", \n",
    "                 \"strong\", \"hyper\", \"explosive\", \"fiery\",\n",
    "                \"raucous\", \"bombastic\", \"rambunctious\", \"reckless\", \"thrilling\", \"rollicking\",\n",
    "                 \"rowdy\", \"sprawling\", \"gutsy\", \"bravado\", \"animated\", \"mighty\", \n",
    "                 \"kinetic\", \"marching\"]\n",
    "calm = ['mellow', 'relaxed', \"consoling\",'airy','dreamy', 'smooth', 'soft', 'atmospheric', 'ethereal', 'calm', 'soothing', 'lazy', 'gentle', 'reflective', 'quiet', 'spiritual', 'introspective', 'delicate', 'peaceful', 'nocturnal', 'lyrical', 'elegant', 'meditative', 'pure', 'cerebral', 'sparse', 'unsettling', 'philosophical', 'flowing', 'laid-back', 'detached', 'innocent', 'austere', 'reassuring', 'reserved', 'understated', 'graceful', 'languid', 'meandering', 'monastic', 'tender']\n",
    "\n",
    "sexy = ['sexy', 'romantic', 'sensual', 'lush', 'passionate', 'intimate', 'erotic', 'sexual', 'spicy']\n",
    "\n",
    "angry = ['angry', 'defiant','aggressive', 'fierce', 'sarcastic', 'harsh', 'menacing', 'manic', 'martial', 'brash', 'rebellious', 'confrontational', 'feral', 'trashy', 'volatile', 'demonic', 'savage', 'hostile', 'brassy', 'uncompromising', 'acerbic', 'outrageous', 'malevolent', 'irreverent', 'thuggish', 'outraged', 'bitter', 'gritty']\n",
    "\n",
    "serious = ['dramatic', 'suspenseful', 'tense', 'devotional', \"cathartic\",\"visceral\",'thoughtful', 'mysterious', 'mystical', 'serious', 'provocative', 'paranoid', 'urgent', 'literate', 'narrative', 'confident', 'earnest', 'monumental', 'plaintive', 'searching', 'ambitious', 'difficult', 'pastoral', 'noble', 'reverent', 'resolute', 'restrained', 'dignified']\n",
    "weird = [i for i in unique_tags if all(i not in j for j in categories)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a754827-5cdc-4eea-aa68-6daa6cc46fad",
   "metadata": {},
   "source": [
    "## Load Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ff215e-053f-46c7-bd06-def419fba467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f71e6e-5266-457e-b0c3-bedf9a4b27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')  # Use this to load default distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f349a27b-0077-4c97-afc7-3d61abe16df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'./v{ver}_final_model')  # Use this to load our fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f05ad-864c-40b6-834c-bfd62452fa94",
   "metadata": {},
   "source": [
    "## Preprocess Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90624bc4-531c-443a-829c-eb8e2cff8329",
   "metadata": {},
   "source": [
    "Need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb55f0c7-5eeb-4a6f-a59e-b59345014fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['seeds'] = data['seeds'].apply(lambda i: eval(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266ae38-c603-49f4-a0f1-14c108269b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25c794a-1de1-45f0-b653-cf8df71183aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "buffer = 8\n",
    "question = 'What are the moods evoked by the following song excerpt?'\n",
    "\n",
    "def text_repr(lyrics: str, tags: list) -> list[str]:\n",
    "    tags = tags[:10]  # Trim the number of tags to prevent some errors\n",
    "    extra_tokens = len(tokenizer(f'Q: {question}\\n\\nA: {\", \".join(tags)}{tokenizer.eos_token}')['input_ids'])\n",
    "    this_chunk_size = chunk_size - extra_tokens\n",
    "    all_tokens = tokenizer(lyrics)['input_ids']\n",
    "    chunks = [all_tokens[i:i + this_chunk_size] for i in range(0, len(all_tokens), this_chunk_size)]\n",
    "    chunks = [f'Q: {question}\\n{tokenizer.decode(i)}\\nA: {\", \".join(tags)}{tokenizer.eos_token}' for i in chunks]\n",
    "    chunks = tokenizer(chunks, padding=True, truncation=True, max_length=chunk_size + buffer)['input_ids']\n",
    "    return chunks[:-1]  # Remove last element to avoid misaligned sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee76642-9a01-41c6-955d-afe19fbdb62d",
   "metadata": {},
   "source": [
    "This code creates a training dataset with all lyrics + tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4598c9-923c-4ed3-b3bc-37bc60e2f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c91c90c812f4171a1c90db8b9994cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "prompts = data['Lyric']\n",
    "tags = data['seeds']\n",
    "\n",
    "tokenized_data_expanded = [text_repr(prompts.iloc[i], tags.iloc[i]) for i in tqdm(range(len(prompts)))]\n",
    "tokenized_data = []\n",
    "for i in tokenized_data_expanded:\n",
    "    tokenized_data += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15678282-50d7-4fa8-9680-17d0c4296ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [i for i in tokenized_data if len(i) == chunk_size]  # Remove any data which still isn't the right size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379d9d1-b4b9-4b8b-944b-5fbf8c51ff75",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a008d1b1-ee0e-4a9b-a53d-a8fd5d365eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: scikit-learn in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ce43aa-6bc3-408a-bdf9-3f4ce2a732b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val = train_test_split(tokenized_data, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1688d5-a69a-4dfa-8b32-e96e865099d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the moods evoked by the following song excerpt?\n",
      " me 'Jane'\n",
      "That's not my name\n",
      "That's not my name\n",
      "That's not my name\n",
      "That's not my name\n",
      "\n",
      "They call me 'quiet girl'\n",
      "But I'm a riot\n",
      "Mary, Jo, Lisa\n",
      "Always the same\n",
      "That's not my name\n",
      "That's not my name\n",
      "That's not my name\n",
      "That's not my name\n",
      "\n",
      "Are you calling me darling?\n",
      "Are you calling me bird?\n",
      "\n",
      "They call me 'hell'\n",
      "They call me '\n",
      "A: fun, happy<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233fde4-71f2-4c22-8907-824917512e98",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9b265-47db-4665-a60d-d96005b2c0ad",
   "metadata": {},
   "source": [
    "No need to do this since fine tuning is already complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf561ee-cfcf-4558-bbc2-0d35121652f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6f5bf6-c0b0-410d-a193-91d8e706742f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m      2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      3\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilgpt2-finetuned-v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2645\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2648\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/trainer.py:2677\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2676\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2677\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1075\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1075\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:842\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_layer)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwte\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[1;32m    844\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"distilgpt2-finetuned-v{ver}\",\n",
    "    save_total_limit=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=x_train,\n",
    "    eval_dataset=x_val,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e67a2399-c342-4994-922f-d93549040dc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_final_model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# DO NOT RUN THIS\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.save_model(f'v{ver}_final_model')  # DO NOT RUN THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012c750-d659-4dad-8959-1276081fea65",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0de6d9-cf0c-4ab4-ad64-4127ec1910fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "text_generator = pipeline('text-generation', tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042cb98a-b037-4fe6-ab75-fc9ccfa48469",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "buffer = 8\n",
    "question = 'What are the moods evoked by the following song excerpt?'\n",
    "\n",
    "def process_lyrics(lyrics: str) -> list[str]:\n",
    "    extra_tokens = len(tokenizer(f'Q: {question}\\n\\nA: ')['input_ids'])\n",
    "    this_chunk_size = chunk_size - extra_tokens\n",
    "    all_tokens = tokenizer(lyrics)['input_ids']\n",
    "    chunks = [all_tokens[i:i + this_chunk_size] for i in range(0, len(all_tokens), this_chunk_size)]\n",
    "    chunks = [f'Q: {question}\\n{tokenizer.decode(i)}\\nA: ' for i in chunks]\n",
    "    chunks = tokenizer(chunks, padding=False, truncation=True, max_length=chunk_size + buffer)['input_ids']\n",
    "    return chunks  # Remove last element to avoid misaligned sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9512b8f8-d09b-48b3-8771-279936d788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LYRICS = \"\"\"\n",
    "[Intro: Cardi B, Al \"T\" McLaran & Megan Thee Stallion]\n",
    "Whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house (Hol' up)\n",
    "I said certified freak, seven days a week\n",
    "Wet-ass pussy, make that pullout game weak, woo (Ah)\n",
    "\n",
    "[Chorus: Cardi B]\n",
    "Yeah, yeah, yeah, yeah\n",
    "Yeah, you fuckin' with some wet-ass pussy\n",
    "Bring a bucket and a mop for this wet-ass pussy\n",
    "Give me everything you got for this wet-ass pussy\n",
    "[Verse 1: Cardi B & Megan Thee Stallion]\n",
    "Beat it up, nigga, catch a charge\n",
    "Extra large and extra hard\n",
    "Put this pussy right in your face\n",
    "Swipe your nose like a credit card\n",
    "Hop on top, I wanna ride\n",
    "I do a kegel while it's inside\n",
    "Spit in my mouth, look in my eyes\n",
    "This pussy is wet, come take a dive\n",
    "Tie me up like I'm surprised\n",
    "Let's roleplay, I'll wear a disguise\n",
    "I want you to park that big Mack truck right in this little garage\n",
    "Make it cream, make me scream\n",
    "Out in public, make a scene\n",
    "I don't cook, I don't clean\n",
    "But let me tell you how I got this ring (Ayy, ayy)\n",
    "\n",
    "[Verse 2: Megan Thee Stallion]\n",
    "Gobble me, swallow me, drip down the side of me (Yeah)\n",
    "Quick, jump out 'fore you let it get inside of me (Yeah)\n",
    "I tell him where to put it, never tell him where I'm 'bout to be (Huh)\n",
    "I'll run down on him 'fore I have a nigga runnin' me (Pow, pow, pow)\n",
    "Talk your shit, bite your lip (Yeah)\n",
    "Ask for a car while you ride that dick (While you ride that dick)\n",
    "You really ain't never gotta fuck him for a thang (Yeah)\n",
    "He already made his mind up 'fore he came (Ayy, ah)\n",
    "Now get your boots and your coat for this wet-ass pussy (Ah, ah, ah)\n",
    "He bought a phone just for pictures of this wet-ass pussy (Click, click, click)\n",
    "Paid my tuition just to kiss me on this wet-ass pussy (Mwah, mwah, mwah)\n",
    "Now make it rain if you wanna see some wet-ass pussy (Yeah, yeah)\n",
    "[Verse 3: Cardi B & Megan Thee Stallion]\n",
    "Look, I need a hard hitter, need a deep stroker\n",
    "Need a Henny drinker, need a weed smoker\n",
    "Not a garter snake, I need a king cobra\n",
    "With a hook in it, hope it lean over\n",
    "He got some money, then that's where I'm headed\n",
    "Pussy A1 just like his credit\n",
    "He got a beard, well, I'm tryna wet it\n",
    "I let him taste it, now he diabetic\n",
    "I don't wanna spit, I wanna gulp\n",
    "I wanna gag, I wanna choke\n",
    "I want you to touch that lil' dangly thing that swing in the back of my throat\n",
    "My head game is fire, punani Dasani\n",
    "It's goin' in dry and it's comin' out soggy\n",
    "I ride on that thing like the cops is behind me (Yeah, ah)\n",
    "I spit on his mic and now he tryna sign me, woo\n",
    "\n",
    "[Verse 4: Megan Thee Stallion]\n",
    "Your honor, I'm a freak bitch, handcuffs, leashes\n",
    "Switch my wig, make him feel like he cheatin'\n",
    "Put him on his knees, give him somethin' to believe in\n",
    "Never lost a fight, but I'm lookin' for a beatin' (Ah)\n",
    "In the food chain, I'm the one that eat ya\n",
    "If he ate my ass, he's a bottom-feeder\n",
    "Big D stand for big demeanor\n",
    "I could make ya bust before I ever meet ya\n",
    "If it don't hang, then he can't bang\n",
    "You can't hurt my feelings, but I like pain\n",
    "If he fuck me and ask \"Whose is it?\"\n",
    "When I ride the dick, I'ma spell my name, ah\n",
    "[Chorus: Cardi B]\n",
    "Yeah, yeah, yeah\n",
    "Yeah, you fuckin' with some wet-ass pussy\n",
    "Bring a bucket and a mop for this wet-ass pussy\n",
    "Give me everything you got for this wet-ass pussy\n",
    "Now from the top, make it drop, that's some wet-ass pussy\n",
    "Now get a bucket and a mop, that's some wet-ass pussy\n",
    "I'm talkin' wap, wap, wap, that's some wet-ass pussy\n",
    "Macaroni in a pot, that's some wet-ass pussy, huh\n",
    "\n",
    "[Outro: Al \"T\" McLaran]\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05caa612-19ca-4489-946e-846ea4e560e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_lyrics_chunks = process_lyrics(LYRICS)\n",
    "len(processed_lyrics_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48245de-7592-4833-a260-02bd3074b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the moods evoked by the following song excerpt?\n",
      ", yeah, yeah, yeah\n",
      "Yeah, you fuckin' with some wet-ass pussy\n",
      "Bring a bucket and a mop for this wet-ass pussy\n",
      "Give me everything you got for this wet-ass pussy\n",
      "[Verse 1: Cardi B & Megan Thee Stallion]\n",
      "Beat it up, nigga, catch a charge\n",
      "Extra large and extra hard\n",
      "Put this pussy right in your face\n",
      "Swipe your nose like a credit card\n",
      "Hop on top, I wanna ride\n",
      "I do a kegel\n",
      "A: ________\n",
      "A: aggressive, light, sexy,\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(text_generator(tokenizer.decode(processed_lyrics_chunks[idx]), \n",
    "                     max_length=len(processed_lyrics_chunks[idx]) + 10)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4877b-d26b-4a91-8698-aa756584b19d",
   "metadata": {},
   "source": [
    "1. function to analyze an entire song\n",
    "    - collate tags from all excerpts\n",
    "    - rank tags\n",
    "    - select some number of best tags as output\n",
    "2. function to evaluate model's performance on a single song\n",
    "    - inputs: model's generated text, correct tags from dataset ground truth\n",
    "    - output: numerical score indicating how well the model performed (ideally 0-1)\n",
    "    - could factor in multiple runs per song?\n",
    "3. apply function to all songs in dataset and plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d551a7-a430-4af4-8ec4-b1d64c2dcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST = [\n",
    "    'ive',\n",
    "    'ersatz',\n",
    "    'ery',\n",
    "    'e',\n",
    "    'no',\n",
    "    'ado',\n",
    "    'tri',\n",
    "    'ute',\n",
    "    'ric',\n",
    "    '\"',\n",
    "    'ious',\n",
    "    'izzy',\n",
    "    'su'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c739f1e-f1b1-4b93-9add-e19f2b669e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['wintry',\n",
       " 'warm',\n",
       " 'smooth',\n",
       " 'slick',\n",
       " 'negative',\n",
       " 'epic',\n",
       " 'energetic',\n",
       " 'driving']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_TOKEN = tokenizer(tokenizer.pad_token)['input_ids'][0]\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "def check(word: str) -> bool:\n",
    "    if word == spell.correction(word) and word not in BLACKLIST:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_array(array):\n",
    "    tags_array = []\n",
    "    for i in array:\n",
    "        tags_array += i\n",
    "    return tags_array\n",
    "    \n",
    "def tags_for_excerpt(tokens: list) -> str:\n",
    "    # tokens = tokenizer(excerpt)['input_ids']\n",
    "    excerpt = tokenizer.decode(tokens)\n",
    "    output = text_generator(excerpt, \n",
    "                         max_length=len(tokens) + 10)[0]['generated_text']\n",
    "    response = output[output.rfind('A: ') + 3:]\n",
    "    response_tags = response.split(', ')\n",
    "    response_tags = [i.strip(', \\nÂ') for i in response_tags]\n",
    "    response_tags = list(filter(check, response_tags))\n",
    "    return response_tags\n",
    "\n",
    "import numpy as np\n",
    "def format_tags(tags, num):\n",
    "    unique_tags, counts = np.unique(tags, return_counts=True)\n",
    "    sorted_tags = unique_tags[np.argsort(counts)][::-1]\n",
    "    return list(sorted_tags[:num])\n",
    "\n",
    "def format_lyrics(lyrics):\n",
    "    lyrics_lst = lyrics.split(\"\\n\")\n",
    "    result = [[lyrics_lst[0], 1]]\n",
    "\n",
    "    for i in range(len(lyrics_lst) - 1):\n",
    "        if lyrics_lst[i] != lyrics_lst[i+1] or lyrics_lst[i+1] == '':\n",
    "            result.append([lyrics_lst[i+1], 1])\n",
    "        else:\n",
    "            result[-1][1] += 1\n",
    "\n",
    "    result2 = [i[0] for i in result]\n",
    "    for i in range(len(result)):\n",
    "        if result[i][1] > 1:\n",
    "            result2[i] += f\" (x{result[i][1]})\"\n",
    "    return '\\n'.join(result2)\n",
    "\n",
    "def gen_tags(lyrics: str, num_tags: int) -> list[list[str]]:\n",
    "    lyrics = format_lyrics(lyrics)\n",
    "    chunks = process_lyrics(lyrics)\n",
    "    result = [tags_for_excerpt(i) for i in chunks]\n",
    "    \n",
    "    tags_array = flatten_array(result)\n",
    "    \n",
    "    return format_tags(tags_array, num_tags)\n",
    "\n",
    "def process_user(lyrics_arr):\n",
    "    return format_tags(flatten_array(map(lambda i: gen_tags(i, 8), lyrics_arr)), 10)\n",
    "\n",
    "\n",
    "tags = process_user([LYRICS])\n",
    "tags\n",
    "#print(format_lyrics(LYRICS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e5a62",
   "metadata": {},
   "source": [
    "Let's say we make a function song_analysis_pipeline(song_lyrics, num_tags_to_select).\n",
    "\n",
    "For each dataset element:\n",
    "\n",
    "- Lyrics\n",
    "- Correct tags\n",
    "\n",
    "Count correct tags, results = song_analysis_pipeline(Lyrics, len(correct_tags)).\n",
    "\n",
    "score = number of tags in results which are also in correct_tags / total number of correct tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4705ea7-aa18-456d-8839-e551f01d82a8",
   "metadata": {},
   "source": [
    "## Result Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "787b5da1-7473-40c9-9a13-0fd1b825b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>102564</td>\n",
       "      <td>https://www.last.fm/music/matt%2bnathanson/_/p...</td>\n",
       "      <td>Pretty The World</td>\n",
       "      <td>Matt Nathanson</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>6</td>\n",
       "      <td>6.881667</td>\n",
       "      <td>5.508333</td>\n",
       "      <td>5.911667</td>\n",
       "      <td>10378a05-dc19-41d9-991f-5fc32cc129f2</td>\n",
       "      <td>3hIvTbJ4iGntLV0LAKIXJz</td>\n",
       "      <td>singer-songwriter</td>\n",
       "      <td>they tied off your arms\\nwith all their pretty...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>75318</td>\n",
       "      <td>https://www.last.fm/music/foals/_/2%2btrees</td>\n",
       "      <td>2 Trees</td>\n",
       "      <td>Foals</td>\n",
       "      <td>[epic]</td>\n",
       "      <td>5</td>\n",
       "      <td>5.936753</td>\n",
       "      <td>4.554545</td>\n",
       "      <td>4.913506</td>\n",
       "      <td>5107ad8b-2c29-4a33-9bf8-e59d2fb03a14</td>\n",
       "      <td>3DI8qieLlMARmGlZX0pWOs</td>\n",
       "      <td>indie rock</td>\n",
       "      <td>Help yourself, help the rest\\nGive blood away,...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>62419</td>\n",
       "      <td>https://www.last.fm/music/the%2bstring%2bquart...</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>The String Quartet</td>\n",
       "      <td>[relaxed]</td>\n",
       "      <td>2</td>\n",
       "      <td>6.822500</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>7.022500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "      <td>Look at the stars\\nLook how they shine for you...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>124966</td>\n",
       "      <td>https://www.last.fm/music/katie%2bmelua/_/just...</td>\n",
       "      <td>Just Like Heaven</td>\n",
       "      <td>Katie Melua</td>\n",
       "      <td>[romantic]</td>\n",
       "      <td>14</td>\n",
       "      <td>5.463661</td>\n",
       "      <td>3.847143</td>\n",
       "      <td>5.782143</td>\n",
       "      <td>2636c1a3-74d7-44ac-8fb8-779fe2a0052b</td>\n",
       "      <td>2tHj8vYlXs8bpqeaHHqUAZ</td>\n",
       "      <td>jazz</td>\n",
       "      <td>Well show me show me\\nshow me how you do that ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>56734</td>\n",
       "      <td>https://www.last.fm/music/richey%2bhackett/_/o...</td>\n",
       "      <td>Obvious</td>\n",
       "      <td>Richey Hackett</td>\n",
       "      <td>[introspective]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.715000</td>\n",
       "      <td>1.805000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronica</td>\n",
       "      <td>Can you hear it in my voice\\nWas it something ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>33659</td>\n",
       "      <td>https://www.last.fm/music/placebo/_/without%2b...</td>\n",
       "      <td>Without You I'm Nothing (feat. David Bowie)</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>[bitter]</td>\n",
       "      <td>6</td>\n",
       "      <td>3.585169</td>\n",
       "      <td>3.982119</td>\n",
       "      <td>3.959831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alternative rock</td>\n",
       "      <td>Strange infatuation seems to grace the evening...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10944</th>\n",
       "      <td>132200</td>\n",
       "      <td>https://www.last.fm/music/lady%2bgaga/_/i%2bli...</td>\n",
       "      <td>I Like It Rough</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>[sexy]</td>\n",
       "      <td>6</td>\n",
       "      <td>7.424118</td>\n",
       "      <td>6.274706</td>\n",
       "      <td>6.114706</td>\n",
       "      <td>df5218ab-8453-4061-ab0c-f991c1afc59b</td>\n",
       "      <td>2FABVB96EnV25oBToWNUk4</td>\n",
       "      <td>pop</td>\n",
       "      <td>Your love is nothing I can't fight\\nCan't slee...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>144855</td>\n",
       "      <td>https://www.last.fm/music/menace%2bruine/_/the...</td>\n",
       "      <td>The Upper Hand</td>\n",
       "      <td>Menace Ruine</td>\n",
       "      <td>[martial]</td>\n",
       "      <td>1</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>4.590000</td>\n",
       "      <td>8ae73adb-7b32-4256-a305-098e825c901a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>martial industrial</td>\n",
       "      <td>Since you've been fifteen you were confused,\\n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15760</th>\n",
       "      <td>213162</td>\n",
       "      <td>https://www.last.fm/music/dead%2bkennedys/_/sh...</td>\n",
       "      <td>Shrink</td>\n",
       "      <td>Dead Kennedys</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>1</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4XM7fdxzWFITBJJQSafVPY</td>\n",
       "      <td>punk</td>\n",
       "      <td>If only people could shrink\\nOur world wouldn'...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>117847</td>\n",
       "      <td>https://www.last.fm/music/lexaunculpt/_/tell%2...</td>\n",
       "      <td>Tell Me You Love Me</td>\n",
       "      <td>Lexaunculpt</td>\n",
       "      <td>[erotic]</td>\n",
       "      <td>2</td>\n",
       "      <td>6.615000</td>\n",
       "      <td>6.810000</td>\n",
       "      <td>6.105000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>idm</td>\n",
       "      <td>Oh no, here we go again\\nFighting over what I ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         lastfm_url  \\\n",
       "9068       102564  https://www.last.fm/music/matt%2bnathanson/_/p...   \n",
       "6729        75318        https://www.last.fm/music/foals/_/2%2btrees   \n",
       "5553        62419  https://www.last.fm/music/the%2bstring%2bquart...   \n",
       "10373      124966  https://www.last.fm/music/katie%2bmelua/_/just...   \n",
       "5099        56734  https://www.last.fm/music/richey%2bhackett/_/o...   \n",
       "...           ...                                                ...   \n",
       "3314        33659  https://www.last.fm/music/placebo/_/without%2b...   \n",
       "10944      132200  https://www.last.fm/music/lady%2bgaga/_/i%2bli...   \n",
       "11816      144855  https://www.last.fm/music/menace%2bruine/_/the...   \n",
       "15760      213162  https://www.last.fm/music/dead%2bkennedys/_/sh...   \n",
       "10078      117847  https://www.last.fm/music/lexaunculpt/_/tell%2...   \n",
       "\n",
       "                                             track              artist  \\\n",
       "9068                              Pretty The World      Matt Nathanson   \n",
       "6729                                       2 Trees               Foals   \n",
       "5553                                        Yellow  The String Quartet   \n",
       "10373                             Just Like Heaven         Katie Melua   \n",
       "5099                                       Obvious      Richey Hackett   \n",
       "...                                            ...                 ...   \n",
       "3314   Without You I'm Nothing (feat. David Bowie)             Placebo   \n",
       "10944                              I Like It Rough           Lady Gaga   \n",
       "11816                               The Upper Hand        Menace Ruine   \n",
       "15760                                       Shrink       Dead Kennedys   \n",
       "10078                          Tell Me You Love Me         Lexaunculpt   \n",
       "\n",
       "                 seeds  number_of_emotion_tags  valence_tags  arousal_tags  \\\n",
       "9068        [positive]                       6      6.881667      5.508333   \n",
       "6729            [epic]                       5      5.936753      4.554545   \n",
       "5553         [relaxed]                       2      6.822500      2.730000   \n",
       "10373       [romantic]                      14      5.463661      3.847143   \n",
       "5099   [introspective]                       2      1.715000      1.805000   \n",
       "...                ...                     ...           ...           ...   \n",
       "3314          [bitter]                       6      3.585169      3.982119   \n",
       "10944           [sexy]                       6      7.424118      6.274706   \n",
       "11816        [martial]                       1      5.400000      4.230000   \n",
       "15760      [energetic]                       1      7.570000      6.100000   \n",
       "10078         [erotic]                       2      6.615000      6.810000   \n",
       "\n",
       "       dominance_tags                                  mbid  \\\n",
       "9068         5.911667  10378a05-dc19-41d9-991f-5fc32cc129f2   \n",
       "6729         4.913506  5107ad8b-2c29-4a33-9bf8-e59d2fb03a14   \n",
       "5553         7.022500                                   NaN   \n",
       "10373        5.782143  2636c1a3-74d7-44ac-8fb8-779fe2a0052b   \n",
       "5099         2.720000                                   NaN   \n",
       "...               ...                                   ...   \n",
       "3314         3.959831                                   NaN   \n",
       "10944        6.114706  df5218ab-8453-4061-ab0c-f991c1afc59b   \n",
       "11816        4.590000  8ae73adb-7b32-4256-a305-098e825c901a   \n",
       "15760        5.810000                                   NaN   \n",
       "10078        6.105000                                   NaN   \n",
       "\n",
       "                   spotify_id               genre  \\\n",
       "9068   3hIvTbJ4iGntLV0LAKIXJz   singer-songwriter   \n",
       "6729   3DI8qieLlMARmGlZX0pWOs          indie rock   \n",
       "5553                      NaN           classical   \n",
       "10373  2tHj8vYlXs8bpqeaHHqUAZ                jazz   \n",
       "5099                      NaN         electronica   \n",
       "...                       ...                 ...   \n",
       "3314                      NaN    alternative rock   \n",
       "10944  2FABVB96EnV25oBToWNUk4                 pop   \n",
       "11816                     NaN  martial industrial   \n",
       "15760  4XM7fdxzWFITBJJQSafVPY                punk   \n",
       "10078                     NaN                 idm   \n",
       "\n",
       "                                                   Lyric language  \n",
       "9068   they tied off your arms\\nwith all their pretty...       en  \n",
       "6729   Help yourself, help the rest\\nGive blood away,...       en  \n",
       "5553   Look at the stars\\nLook how they shine for you...       en  \n",
       "10373  Well show me show me\\nshow me how you do that ...       en  \n",
       "5099   Can you hear it in my voice\\nWas it something ...       en  \n",
       "...                                                  ...      ...  \n",
       "3314   Strange infatuation seems to grace the evening...       en  \n",
       "10944  Your love is nothing I can't fight\\nCan't slee...       en  \n",
       "11816  Since you've been fifteen you were confused,\\n...       en  \n",
       "15760  If only people could shrink\\nOur world wouldn'...       en  \n",
       "10078  Oh no, here we go again\\nFighting over what I ...       en  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = data.sample(1000)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b830036-6b12-4677-b2bb-3859eac480f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bb2a6996ee4628b88da68ed046181b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLyric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tags \u001b[38;5;241m=\u001b[39m evaluation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLyric\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m i: \u001b[43mgen_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[21], line 53\u001b[0m, in \u001b[0;36mgen_tags\u001b[0;34m(lyrics, num_tags)\u001b[0m\n\u001b[1;32m     51\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m format_lyrics(lyrics)\n\u001b[1;32m     52\u001b[0m chunks \u001b[38;5;241m=\u001b[39m process_lyrics(lyrics)\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtags_for_excerpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     55\u001b[0m tags_array \u001b[38;5;241m=\u001b[39m flatten_array(result)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_tags(tags_array, num_tags)\n",
      "Cell \u001b[0;32mIn[21], line 53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m format_lyrics(lyrics)\n\u001b[1;32m     52\u001b[0m chunks \u001b[38;5;241m=\u001b[39m process_lyrics(lyrics)\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[43mtags_for_excerpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     55\u001b[0m tags_array \u001b[38;5;241m=\u001b[39m flatten_array(result)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_tags(tags_array, num_tags)\n",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m, in \u001b[0;36mtags_for_excerpt\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtags_for_excerpt\u001b[39m(tokens: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# tokens = tokenizer(excerpt)['input_ids']\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     excerpt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(tokens)\n\u001b[0;32m---> 20\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mtext_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcerpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m     response \u001b[38;5;241m=\u001b[39m output[output\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA: \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m     23\u001b[0m     response_tags \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:209\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1115\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1116\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py:1015\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1014\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1015\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:251\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/generation/utils.py:1452\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1445\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1446\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1447\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1448\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1449\u001b[0m     )\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/generation/utils.py:2468\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2465\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2468\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1075\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1075\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:899\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    889\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    890\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    891\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    897\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    388\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 389\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:330\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    333\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:211\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op otherwise\u001b[39;00m\n\u001b[1;32m    210\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m attn_weights\u001b[38;5;241m.\u001b[39mtype(value\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 211\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_dropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tags = evaluation['Lyric'].progress_apply(lambda i: gen_tags(i, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "246967b8-5e31-496e-8651-d20d989afe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tags = np.concatenate(list(tags))\n",
    "unique_tags, counts = np.unique(all_tags, return_counts=True)\n",
    "plt.scatter(np.arange(counts.shape[0]), counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "99778743-dff8-45c8-8639-a1c5cd3d9fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'ado', 'crunchy', 'philosophical', 'apocalyptic', 'harsh',\n",
       "       'bitters', 'clinical', 'tense', 'brash', 'tri', 'urgent',\n",
       "       'ominous', 'sens', 'lonely', 'cold', 'euphoric', 'defiant',\n",
       "       'provocative', 'ute', 'freewheeling', 'celebratory', 'airy',\n",
       "       'delicate', 'naive', 'elaborate', 'lazy', 'gloomy', 'meditative',\n",
       "       'exuberant', 'sleazy', 'joyous', 'gritty', 'aggressive',\n",
       "       'technical', 'eerie', 'sacred', 'brooding', 'thrilling', 'ric',\n",
       "       'somber', 'sparse', 'spooky', 'whimsical', '\"', 'comic',\n",
       "       'menacing', 'precious', 'refined', 'earnest', 'paranoid',\n",
       "       'summery', 'complex', 'exciting', 'introspective', 'grim',\n",
       "       'flowing', 'detached', 'scary', 'desperate', 'organic',\n",
       "       'halloween', 'pure', 'fiery', 'ious', 'mysterious', 'lively',\n",
       "       'autumnal', 'cerebral', 'manic', 'negative', 'stylish',\n",
       "       'narrative', 'dreamy', 'literate', 'wry', 'sardonic', 'fierce',\n",
       "       'sarcastic', 'angry', 'strong', 'dark', 'humorous', 'ironic',\n",
       "       'intimate', 'triumphant', 'relaxed', 'lyrical', 'silly', 'intense',\n",
       "       'cheerful', 'uplifting', 'spiritual', 'mystical', 'bitter',\n",
       "       'tragic', 'theatrical', 'elegant', 'playful', 'cathartic',\n",
       "       'exotic', 'gentle', 'cynical', 'sophisticated', 'slick',\n",
       "       'ethereal', 'rousing', 'yearning', 'fun', 'nocturnal', 'confident',\n",
       "       'positive', 'happy', 'bright', 'lush', 'optimistic', 'eccentric',\n",
       "       'soothing', 'sexual', 'sexy', 'erotic', 'dramatic', 'tender',\n",
       "       'flashy', 'epic', 'passionate', 'trippy', 'hypnotic', 'mellow',\n",
       "       'thoughtful', 'warm', 'wistful', 'romantic', 'peaceful', 'quirky',\n",
       "       'melancholy', 'witty', 'bittersweet', 'light', 'sensual',\n",
       "       'nostalgic', 'sad', 'atmospheric', 'energetic', 'reflective',\n",
       "       'poignant', 'driving', 'powerful', 'iced', 'smooth', 'sentimental',\n",
       "       'sweet', 'quiet', 'calm', 'soft'], dtype='<U60')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floor_tags, floor_counts = unique_tags[counts > 5], counts[counts > 5]\n",
    "average_freqs = floor_counts / 1000\n",
    "sort = np.argsort(floor_counts)\n",
    "tags_weighted = floor_tags[sort]\n",
    "tags_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0253a122-00cd-40c0-a28f-cdef27471925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['philosophical', 'apocalyptic', 'bitters', 'crunchy', 'harsh',\n",
       "       'lonely', 'urgent', 'tense', 'brash', 'sens', 'ominous',\n",
       "       'clinical', 'provocative', 'freewheeling', 'defiant', 'cold',\n",
       "       'euphoric', 'celebratory', 'naive', 'airy', 'elaborate',\n",
       "       'delicate', 'exuberant', 'sleazy', 'gloomy', 'meditative', 'lazy',\n",
       "       'aggressive', 'gritty', 'joyous', 'technical', 'eerie', 'sacred',\n",
       "       'thrilling', 'brooding', 'whimsical', 'somber', 'spooky', 'sparse',\n",
       "       'precious', 'comic', 'menacing', 'refined', 'earnest', 'summery',\n",
       "       'paranoid', 'introspective', 'complex', 'exciting', 'scary',\n",
       "       'grim', 'desperate', 'flowing', 'detached', 'organic', 'halloween',\n",
       "       'pure', 'mysterious', 'fiery', 'lively', 'autumnal', 'negative',\n",
       "       'manic', 'cerebral', 'dreamy', 'sardonic', 'narrative', 'stylish',\n",
       "       'literate', 'wry', 'fierce', 'sarcastic', 'angry', 'strong',\n",
       "       'dark', 'humorous', 'relaxed', 'intimate', 'triumphant', 'ironic',\n",
       "       'lyrical', 'silly', 'intense', 'cheerful', 'uplifting',\n",
       "       'spiritual', 'mystical', 'tragic', 'bitter', 'theatrical',\n",
       "       'elegant', 'playful', 'cathartic', 'exotic', 'cynical', 'gentle',\n",
       "       'sophisticated', 'slick', 'rousing', 'ethereal', 'fun', 'yearning',\n",
       "       'nocturnal', 'confident', 'positive', 'happy', 'optimistic',\n",
       "       'bright', 'lush', 'eccentric', 'soothing', 'sexual', 'sexy',\n",
       "       'erotic', 'tender', 'dramatic', 'flashy', 'passionate', 'epic',\n",
       "       'trippy', 'hypnotic', 'mellow', 'thoughtful', 'warm', 'wistful',\n",
       "       'romantic', 'peaceful', 'quirky', 'melancholy', 'witty',\n",
       "       'bittersweet', 'light', 'sensual', 'nostalgic', 'sad',\n",
       "       'atmospheric', 'energetic', 'reflective', 'poignant', 'driving',\n",
       "       'powerful', 'iced', 'smooth', 'sentimental', 'sweet', 'quiet',\n",
       "       'calm', 'soft'], dtype='<U60')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Had to update blacklist\n",
    "blacklist_mask = [i not in BLACKLIST for i in floor_tags]\n",
    "tags_no_blacklist, freqs_no_blacklist = floor_tags[blacklist_mask], average_freqs[blacklist_mask]\n",
    "sort = np.argsort(freqs_no_blacklist)\n",
    "tags_weighted = tags_no_blacklist[sort]\n",
    "freqs_sorted = freqs_no_blacklist[sort]\n",
    "tags_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6e08ff18-4705-4e0d-bb61-000e1c535e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.006, 0.006, 0.006, 0.006, 0.006, 0.007, 0.007, 0.007, 0.007,\n",
       "       0.007, 0.007, 0.007, 0.008, 0.008, 0.008, 0.008, 0.008, 0.009,\n",
       "       0.009, 0.009, 0.009, 0.009, 0.01 , 0.01 , 0.01 , 0.01 , 0.01 ,\n",
       "       0.011, 0.011, 0.011, 0.012, 0.012, 0.013, 0.013, 0.013, 0.014,\n",
       "       0.014, 0.014, 0.014, 0.015, 0.015, 0.015, 0.016, 0.016, 0.017,\n",
       "       0.017, 0.018, 0.018, 0.018, 0.019, 0.019, 0.019, 0.019, 0.019,\n",
       "       0.02 , 0.021, 0.022, 0.022, 0.022, 0.023, 0.023, 0.024, 0.024,\n",
       "       0.024, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.032, 0.032, 0.032, 0.035,\n",
       "       0.036, 0.036, 0.037, 0.037, 0.038, 0.039, 0.04 , 0.04 , 0.041,\n",
       "       0.042, 0.042, 0.043, 0.045, 0.046, 0.046, 0.048, 0.049, 0.05 ,\n",
       "       0.05 , 0.054, 0.054, 0.055, 0.056, 0.056, 0.062, 0.062, 0.062,\n",
       "       0.062, 0.064, 0.067, 0.069, 0.069, 0.07 , 0.072, 0.072, 0.074,\n",
       "       0.079, 0.079, 0.08 , 0.085, 0.09 , 0.092, 0.093, 0.098, 0.106,\n",
       "       0.115, 0.117, 0.119, 0.12 , 0.127, 0.139, 0.141, 0.15 , 0.151,\n",
       "       0.177, 0.183, 0.189, 0.19 , 0.205, 0.214, 0.222, 0.255, 0.309,\n",
       "       0.31 , 0.337, 0.392, 0.504])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "39ef7b52-dd7c-46fd-8cef-04d73035fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {tags_weighted[i]: freqs_sorted[i] for i in range(len(tags_weighted))}\n",
    "\n",
    "import pickle\n",
    "with open('tag_map.data', 'wb') as f:\n",
    "    pickle.dump(tag_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0024925c-48e9-4b3e-889a-3467253607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tag_map.data', 'rb') as f:\n",
    "    tag_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46698c35-ce2b-4698-b9fd-a920cce86ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TAG_WEIGHT = -20\n",
    "TOKENS_TO_GENERATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96e5b4fb-3d60-4bf7-be1d-600b995abc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['provocative',\n",
       " 'exuberant',\n",
       " 'desperate',\n",
       " 'narrative',\n",
       " 'triumphant',\n",
       " 'tragic',\n",
       " 'slick',\n",
       " 'energetic']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_TOKEN = tokenizer(tokenizer.pad_token)['input_ids'][0]\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "def check(word: str) -> bool:\n",
    "    if word == spell.correction(word) and word not in BLACKLIST:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_array(array: list):\n",
    "    tags_array = []\n",
    "    for i in array:\n",
    "        tags_array += i\n",
    "    return tags_array\n",
    "    \n",
    "def tags_for_excerpt(tokens: list) -> str:\n",
    "    # tokens = tokenizer(excerpt)['input_ids']\n",
    "    excerpt = tokenizer.decode(tokens)\n",
    "    output = text_generator(excerpt, \n",
    "                         max_length=len(tokens) + TOKENS_TO_GENERATE)[0]['generated_text']\n",
    "    response = output[output.rfind('A: ') + 3:]\n",
    "    response_tags = response.split(', ')\n",
    "    response_tags = [i.strip(', \\nÂ') for i in response_tags]\n",
    "    response_tags = list(filter(check, response_tags))\n",
    "    return response_tags\n",
    "\n",
    "import numpy as np\n",
    "def select_tags(tags: list, num: int):\n",
    "    unique_tags, counts = np.unique(tags, return_counts=True)\n",
    "    \n",
    "    freq_diffs = []\n",
    "    for i in range(len(unique_tags)):\n",
    "        if unique_tags[i] in tag_map.keys():\n",
    "            freq_diffs.append(counts[i] / len(tags) - tag_map[unique_tags[i]])\n",
    "        else:\n",
    "            freq_diffs.append(UNK_TAG_WEIGHT)\n",
    "    sorted_tags = unique_tags[np.argsort(freq_diffs)][::-1]\n",
    "    return list(sorted_tags[:num])\n",
    "\n",
    "def format_lyrics(lyrics):\n",
    "    lyrics_lst = lyrics.split(\"\\n\")\n",
    "    result = [[lyrics_lst[0], 1]]\n",
    "\n",
    "    for i in range(len(lyrics_lst) - 1):\n",
    "        if lyrics_lst[i] != lyrics_lst[i+1] or lyrics_lst[i+1] == '':\n",
    "            result.append([lyrics_lst[i+1], 1])\n",
    "        else:\n",
    "            result[-1][1] += 1\n",
    "\n",
    "    result2 = [i[0] for i in result]\n",
    "    for i in range(len(result)):\n",
    "        if result[i][1] > 1:\n",
    "            result2[i] += f\" (x{result[i][1]})\"\n",
    "    return '\\n'.join(result2)\n",
    "\n",
    "# generates tags for a single song\n",
    "def gen_tags(lyrics: str, num_tags: int) -> list[list[str]]:\n",
    "    lyrics = format_lyrics(lyrics)\n",
    "    chunks = process_lyrics(lyrics)\n",
    "    result = [tags_for_excerpt(i) for i in chunks]\n",
    "    \n",
    "    tags_array = flatten_array(result)\n",
    "    \n",
    "    return select_tags(tags_array, num_tags)\n",
    "\n",
    "def process_user(lyrics_arr):\n",
    "    return select_tags(flatten_array(map(lambda i: gen_tags(i, 8), lyrics_arr)), 10)\n",
    "\n",
    "\n",
    "tags = process_user([LYRICS])\n",
    "tags\n",
    "#print(format_lyrics(LYRICS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a597c45-beb9-419c-9663-7e8f51d9b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['provocative',\n",
       " 'brash',\n",
       " 'clinical',\n",
       " 'ominous',\n",
       " 'euphoric',\n",
       " 'delicate',\n",
       " 'precious',\n",
       " 'gloomy']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def high_fidelity_gen_tags(lyrics, num_tags):\n",
    "    all_tags = []\n",
    "    for i in range(10):\n",
    "        lyrics = format_lyrics(lyrics)\n",
    "        chunks = process_lyrics(lyrics)\n",
    "        result = [tags_for_excerpt(i) for i in chunks]\n",
    "\n",
    "        tags_array = flatten_array(result)\n",
    "        all_tags += tags_array\n",
    "    return select_tags(all_tags, num_tags)\n",
    "\n",
    "high_fidelity_gen_tags(LYRICS, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d857f4f-78d5-400e-9885-e0322ab8da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_tags = [\"melancholy\", \"sad\", \"bittersweet\", \"sentimental\", \"cynical\", \"nostalgic\",\n",
    "            \"lonely\", 'regretful',\"sardonic\", \"poignant\", \"gloomy\", \"brooding\", \"yearning\",\n",
    "           \"negative\", \"apocalyptic\", \"tragic\", \"bleak\", \"somber\", \"desperate\", \"grim\", \"detached\"\n",
    "           \"fractured\", \"anxious\", \"nihilistic\", \"angst-ridden\", \"nervous\", \"weary\", \"distraught\", \n",
    "           \"self-conscious\", \"funereal\", \"suffocating\", \"elegiac\", \"cold\", \"dark\", 'wistful']\n",
    "happy_tags = [\"happy\", 'light',\"comic\", 'campy', \"fun\", \"sweet\", \"cheerful\", \"warm\", \"positive\", \"silly\", \"playful\", \"optimistic\",\n",
    "            \"bright\", \"humorous\", \"lively\", \"exciting\", \"euphoric\", \"summery\", 'uplifting'\n",
    "             \"joyous\", \"triumphant\", \"carefree\", \"exuberant\", \"ecstatic\", \"sparkling\", \"celebratory\", \n",
    "             \"perky\", \"boisterous\", \"swaggering\", \"sugary\", \"amiable\", \"good-natured\", \"gleeful\",\n",
    "             \"agreeable\", \"jovial\", \"giddy\", \"ebullient\", \"effervescent\", 'whimsical']\n",
    "energetic_tags = [\"epic\", \"intense\", \"powerful\", \"energetic\", \"driving\", \"rousing\", \n",
    "                 \"strong\", \"hyper\", \"explosive\", \"fiery\",\n",
    "                \"raucous\", \"bombastic\", \"rambunctious\", \"reckless\", \"thrilling\", \"rollicking\",\n",
    "                 \"rowdy\", \"sprawling\", \"gutsy\", \"bravado\", \"animated\", \"mighty\", \n",
    "                 \"kinetic\", \"marching\"]\n",
    "calm_tags = ['mellow', 'relaxed', \"consoling\",'airy','dreamy', 'smooth', 'soft', 'atmospheric', 'ethereal', 'calm', 'soothing', 'lazy', 'gentle', 'reflective', 'quiet', 'spiritual', 'introspective', 'delicate', 'peaceful', 'nocturnal', 'lyrical', 'elegant', 'meditative', 'pure', 'cerebral', 'sparse', 'unsettling', 'philosophical', 'flowing', 'laid-back', 'detached', 'innocent', 'austere', 'reassuring', 'reserved', 'understated', 'graceful', 'languid', 'meandering', 'monastic', 'tender']\n",
    "\n",
    "sexy_tags = ['sexy', 'romantic', 'sensual', 'lush', 'passionate', 'intimate', 'erotic', 'sexual', 'spicy']\n",
    "\n",
    "angry_tags = ['angry', 'defiant','aggressive', 'fierce', 'sarcastic', 'harsh', 'menacing', 'manic', 'martial', 'brash', 'rebellious', 'confrontational', 'feral', 'trashy', 'volatile', 'demonic', 'savage', 'hostile', 'brassy', 'uncompromising', 'acerbic', 'outrageous', 'malevolent', 'irreverent', 'thuggish', 'outraged', 'bitter', 'gritty']\n",
    "\n",
    "serious_tags = ['dramatic', 'suspenseful', 'tense', 'devotional', \"cathartic\",\"visceral\",'thoughtful', 'mysterious', 'mystical', 'serious', 'provocative', 'paranoid', 'urgent', 'literate', 'narrative', 'confident', 'earnest', 'monumental', 'plaintive', 'searching', 'ambitious', 'difficult', 'pastoral', 'noble', 'reverent', 'resolute', 'restrained', 'dignified']\n",
    "\n",
    "def classify_tag(tag):\n",
    "    if tag in sad_tags:\n",
    "        return 'sad'\n",
    "    elif tag in happy_tags:\n",
    "        return 'happy'\n",
    "    elif tag in energetic_tags:\n",
    "        return 'energetic'\n",
    "    elif tag in calm_tags:\n",
    "        return 'calm'\n",
    "    elif tag in sexy_tags:\n",
    "        return 'sexy'\n",
    "    elif tag in angry_tags:\n",
    "        return 'angry'\n",
    "    elif tag in serious_tags:\n",
    "        return 'serious'\n",
    "    else:\n",
    "        return 'werid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f59630bd-2a22-40e7-97fc-ad30c5f91826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['calm', 'happy', 'sad', 'sexy', 'werid'], dtype='<U5')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate(row):\n",
    "    tags = gen_tags(row['Lyric'], 8)\n",
    "    tags = [classify_tag(i) for i in tags]\n",
    "    return np.unique(tags)\n",
    "\n",
    "validate(data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99867e00-a2ca-4d02-a10c-ec8a14ab1aa9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deabba61115d4827981ac0ff4dc76d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/var/folders/kj/6vhd10m96gq74ffmkjkxlkq80000gn/T/ipykernel_24140/2261094707.py:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  scores.append(sum([j in pred for j in true]) / len(true))\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "       1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.5       ,\n",
       "       1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.33333333, 1.        ,\n",
       "       0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.5       , 0.        , 1.        , 0.5       , 0.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       0.        , 0.5       , 1.        , 0.        , 1.        ,\n",
       "       0.33333333, 0.        , 0.        , 1.        , 0.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "sample = data.sample(100)\n",
    "scores = []\n",
    "for i in tqdm(range(len(sample))):\n",
    "    row = sample.iloc[i]\n",
    "    pred = validate(row)\n",
    "    true = [classify_tag(i) for i in row['seeds']]\n",
    "    # Average fraction of each song's tags which the model CORRECTLY PREDICTED\n",
    "    scores.append(np.mean([j in pred for j in true]))\n",
    "scores = np.array(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "438a1710-a8f1-4430-be03-ae60d530a323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6066666666666667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4de8e0fc-fe02-48d2-ba7c-f5a6095a79c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[classify_tag(i) for i in data.iloc[0]['seeds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea844fa-74d1-4f78-b95e-6e5fa31506e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
