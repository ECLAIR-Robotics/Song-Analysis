{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c78a7fb-edce-4a67-917a-f0099a9303d8",
   "metadata": {},
   "source": [
    "# distilGPT2 Fine-Tuning v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe50c734-113a-416e-a590-b8a5f6cbb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "ver = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b86845-b402-41ed-9572-764d6a99b09c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94eee7e-3c43-43e4-bc11-58efce82e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.last.fm/music/metallica/_/st.%2banger</td>\n",
       "      <td>St. Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>727a2529-7ee8-4860-aef6-7959884895cb</td>\n",
       "      <td>3fOc9x06lKJBhz435mInlH</td>\n",
       "      <td>metal</td>\n",
       "      <td>Saint Anger 'round my neck\\nSaint Anger 'round...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.last.fm/music/m.i.a./_/bamboo%2bbanga</td>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>['aggressive', 'fun', 'sexy', 'energetic']</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>99dd2c8c-e7c1-413e-8ea4-4497a00ffa18</td>\n",
       "      <td>6tqFC1DIOphJkCwrjVzPmg</td>\n",
       "      <td>hip-hop</td>\n",
       "      <td>Road runner, road runner\\nGoing hundred mile p...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.last.fm/music/drowning%2bpool/_/st...</td>\n",
       "      <td>Step Up</td>\n",
       "      <td>Drowning Pool</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>9</td>\n",
       "      <td>2.971389</td>\n",
       "      <td>5.537500</td>\n",
       "      <td>4.726389</td>\n",
       "      <td>49e7b4d2-3772-4301-ba25-3cc46ceb342e</td>\n",
       "      <td>4Q1w4Ryyi8KNxxaFlOQClK</td>\n",
       "      <td>metal</td>\n",
       "      <td>Come!\\n\\nIf our own lives aren’t directly affe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>https://www.last.fm/music/kanye%2bwest/_/feedback</td>\n",
       "      <td>Feedback</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49fT6owWuknekShh9utsjv</td>\n",
       "      <td>hip-hop</td>\n",
       "      <td>Ayy, y'all heard about the good news?\\nY'all s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>https://www.last.fm/music/deftones/_/7%2bwords</td>\n",
       "      <td>7 Words</td>\n",
       "      <td>Deftones</td>\n",
       "      <td>['aggressive', 'angry']</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807121</td>\n",
       "      <td>5.473939</td>\n",
       "      <td>4.729091</td>\n",
       "      <td>1a826083-5585-445f-a708-415dc90aa050</td>\n",
       "      <td>6DoXuH326aAYEN8CnlLmhP</td>\n",
       "      <td>nu metal</td>\n",
       "      <td>I'll never be the same, breaking decency\\nDon'...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16792</th>\n",
       "      <td>229432</td>\n",
       "      <td>https://www.last.fm/music/noblegases/_/xenon</td>\n",
       "      <td>Xenon</td>\n",
       "      <td>NobleGases</td>\n",
       "      <td>['noble']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.160000</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>6.130000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1AePjgLLtzF0abbfcgYdLI</td>\n",
       "      <td>chill</td>\n",
       "      <td>You're floating out astray\\nThis cold and life...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16793</th>\n",
       "      <td>229435</td>\n",
       "      <td>https://www.last.fm/music/kurt%2bvile/_/wild%2...</td>\n",
       "      <td>Wild Imagination</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.925000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>6.190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1Gn0oYQiQHp7KF4DcR2g4t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm looking at you\\nBut It's only a picture so...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16794</th>\n",
       "      <td>229436</td>\n",
       "      <td>https://www.last.fm/music/portugal.%2bthe%2bma...</td>\n",
       "      <td>Oh Lord</td>\n",
       "      <td>Portugal. The Man</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>7ea228f9-16d0-474d-8c51-5a1a9810ddde</td>\n",
       "      <td>6YG8cjbrjhDhlYMiQnibUD</td>\n",
       "      <td>indie</td>\n",
       "      <td>\\n\\n\\nWhere do I fit in\\nI am waiting here for...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>229443</td>\n",
       "      <td>https://www.last.fm/music/porcelain%2band%2bth...</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Porcelain and The Tramps</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>3</td>\n",
       "      <td>6.613333</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>5.773333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>industrial</td>\n",
       "      <td>Wish I were transparent\\nYou could see right t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>229473</td>\n",
       "      <td>https://www.last.fm/music/daniel%2blanois/_/lo...</td>\n",
       "      <td>Lovechild</td>\n",
       "      <td>Daniel Lanois</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.685000</td>\n",
       "      <td>4.405000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c</td>\n",
       "      <td>4fVObxldDzxxRD6a5Eth9s</td>\n",
       "      <td>indie</td>\n",
       "      <td>I CAUGHT HER STARING, A PSYCHEDELIC DANCER,\\nG...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16797 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         lastfm_url  \\\n",
       "0               1  https://www.last.fm/music/metallica/_/st.%2banger   \n",
       "1               3  https://www.last.fm/music/m.i.a./_/bamboo%2bbanga   \n",
       "2               5  https://www.last.fm/music/drowning%2bpool/_/st...   \n",
       "3              11  https://www.last.fm/music/kanye%2bwest/_/feedback   \n",
       "4              13     https://www.last.fm/music/deftones/_/7%2bwords   \n",
       "...           ...                                                ...   \n",
       "16792      229432       https://www.last.fm/music/noblegases/_/xenon   \n",
       "16793      229435  https://www.last.fm/music/kurt%2bvile/_/wild%2...   \n",
       "16794      229436  https://www.last.fm/music/portugal.%2bthe%2bma...   \n",
       "16795      229443  https://www.last.fm/music/porcelain%2band%2bth...   \n",
       "16796      229473  https://www.last.fm/music/daniel%2blanois/_/lo...   \n",
       "\n",
       "                  track                    artist  \\\n",
       "0             St. Anger                 Metallica   \n",
       "1          Bamboo Banga                    M.I.A.   \n",
       "2               Step Up             Drowning Pool   \n",
       "3              Feedback                Kanye West   \n",
       "4               7 Words                  Deftones   \n",
       "...                 ...                       ...   \n",
       "16792             Xenon                NobleGases   \n",
       "16793  Wild Imagination                 Kurt Vile   \n",
       "16794           Oh Lord         Portugal. The Man   \n",
       "16795       Transparent  Porcelain and The Tramps   \n",
       "16796         Lovechild             Daniel Lanois   \n",
       "\n",
       "                                            seeds  number_of_emotion_tags  \\\n",
       "0                                  ['aggressive']                       8   \n",
       "1      ['aggressive', 'fun', 'sexy', 'energetic']                      13   \n",
       "2                                  ['aggressive']                       9   \n",
       "3                                  ['aggressive']                       1   \n",
       "4                         ['aggressive', 'angry']                      10   \n",
       "...                                           ...                     ...   \n",
       "16792                                   ['noble']                       2   \n",
       "16793                             ['transparent']                       2   \n",
       "16794                             ['transparent']                       1   \n",
       "16795                             ['transparent']                       3   \n",
       "16796                             ['transparent']                       2   \n",
       "\n",
       "       valence_tags  arousal_tags  dominance_tags  \\\n",
       "0          3.710000      5.833000        5.427250   \n",
       "1          6.555071      5.537214        5.691357   \n",
       "2          2.971389      5.537500        4.726389   \n",
       "3          3.080000      5.870000        5.490000   \n",
       "4          3.807121      5.473939        4.729091   \n",
       "...             ...           ...             ...   \n",
       "16792      6.160000      3.695000        6.130000   \n",
       "16793      6.925000      4.975000        6.190000   \n",
       "16794      5.370000      3.450000        5.330000   \n",
       "16795      6.613333      4.633333        5.773333   \n",
       "16796      6.685000      4.405000        5.625000   \n",
       "\n",
       "                                       mbid              spotify_id  \\\n",
       "0      727a2529-7ee8-4860-aef6-7959884895cb  3fOc9x06lKJBhz435mInlH   \n",
       "1      99dd2c8c-e7c1-413e-8ea4-4497a00ffa18  6tqFC1DIOphJkCwrjVzPmg   \n",
       "2      49e7b4d2-3772-4301-ba25-3cc46ceb342e  4Q1w4Ryyi8KNxxaFlOQClK   \n",
       "3                                       NaN  49fT6owWuknekShh9utsjv   \n",
       "4      1a826083-5585-445f-a708-415dc90aa050  6DoXuH326aAYEN8CnlLmhP   \n",
       "...                                     ...                     ...   \n",
       "16792                                   NaN  1AePjgLLtzF0abbfcgYdLI   \n",
       "16793                                   NaN  1Gn0oYQiQHp7KF4DcR2g4t   \n",
       "16794  7ea228f9-16d0-474d-8c51-5a1a9810ddde  6YG8cjbrjhDhlYMiQnibUD   \n",
       "16795                                   NaN                     NaN   \n",
       "16796  16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c  4fVObxldDzxxRD6a5Eth9s   \n",
       "\n",
       "            genre                                              Lyric language  \n",
       "0           metal  Saint Anger 'round my neck\\nSaint Anger 'round...       en  \n",
       "1         hip-hop  Road runner, road runner\\nGoing hundred mile p...       en  \n",
       "2           metal  Come!\\n\\nIf our own lives aren’t directly affe...       en  \n",
       "3         hip-hop  Ayy, y'all heard about the good news?\\nY'all s...       en  \n",
       "4        nu metal  I'll never be the same, breaking decency\\nDon'...       en  \n",
       "...           ...                                                ...      ...  \n",
       "16792       chill  You're floating out astray\\nThis cold and life...       en  \n",
       "16793         NaN  I'm looking at you\\nBut It's only a picture so...       en  \n",
       "16794       indie  \\n\\n\\nWhere do I fit in\\nI am waiting here for...       en  \n",
       "16795  industrial  Wish I were transparent\\nYou could see right t...       en  \n",
       "16796       indie  I CAUGHT HER STARING, A PSYCHEDELIC DANCER,\\nG...       en  \n",
       "\n",
       "[16797 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../out.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a754827-5cdc-4eea-aa68-6daa6cc46fad",
   "metadata": {},
   "source": [
    "## Load Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ff215e-053f-46c7-bd06-def419fba467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f71e6e-5266-457e-b0c3-bedf9a4b27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')  # Use this to load default distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f349a27b-0077-4c97-afc7-3d61abe16df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'./v{ver}_final_model')  # Use this to load our fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f05ad-864c-40b6-834c-bfd62452fa94",
   "metadata": {},
   "source": [
    "## Preprocess Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90624bc4-531c-443a-829c-eb8e2cff8329",
   "metadata": {},
   "source": [
    "Need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb55f0c7-5eeb-4a6f-a59e-b59345014fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['seeds'] = data['seeds'].apply(lambda i: eval(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266ae38-c603-49f4-a0f1-14c108269b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25c794a-1de1-45f0-b653-cf8df71183aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "buffer = 8\n",
    "question = 'What are the moods evoked by the following song excerpt?'\n",
    "\n",
    "def text_repr(lyrics: str, tags: list) -> list[str]:\n",
    "    tags = tags[:10]  # Trim the number of tags to prevent some errors\n",
    "    extra_tokens = len(tokenizer(f'Q: {question}\\n\\nA: {\", \".join(tags)}{tokenizer.eos_token}')['input_ids'])\n",
    "    this_chunk_size = chunk_size - extra_tokens\n",
    "    all_tokens = tokenizer(lyrics)['input_ids']\n",
    "    chunks = [all_tokens[i:i + this_chunk_size] for i in range(0, len(all_tokens), this_chunk_size)]\n",
    "    chunks = [f'Q: {question}\\n{tokenizer.decode(i)}\\nA: {\", \".join(tags)}{tokenizer.eos_token}' for i in chunks]\n",
    "    chunks = tokenizer(chunks, padding=True, truncation=True, max_length=chunk_size + buffer)['input_ids']\n",
    "    return chunks[:-1]  # Remove last element to avoid misaligned sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee76642-9a01-41c6-955d-afe19fbdb62d",
   "metadata": {},
   "source": [
    "This code creates a training dataset with all lyrics + tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4598c9-923c-4ed3-b3bc-37bc60e2f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0b99613d154fbf99f22e3a7ae9d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "prompts = data['Lyric']\n",
    "tags = data['seeds']\n",
    "\n",
    "tokenized_data_expanded = [text_repr(prompts.iloc[i], tags.iloc[i]) for i in tqdm(range(len(prompts)))]\n",
    "tokenized_data = []\n",
    "for i in tokenized_data_expanded:\n",
    "    tokenized_data += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15678282-50d7-4fa8-9680-17d0c4296ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [i for i in tokenized_data if len(i) == chunk_size]  # Remove any data which still isn't the right size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379d9d1-b4b9-4b8b-944b-5fbf8c51ff75",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a008d1b1-ee0e-4a9b-a53d-a8fd5d365eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-macosx_12_0_arm64.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/sarah/miniconda3/envs/torch/lib/python3.11/site-packages (from scikit-learn) (1.24.2)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.1-cp311-cp311-macosx_12_0_arm64.whl (28.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.7/28.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ce43aa-6bc3-408a-bdf9-3f4ce2a732b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val = train_test_split(tokenized_data, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1688d5-a69a-4dfa-8b32-e96e865099d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mx_train\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233fde4-71f2-4c22-8907-824917512e98",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9b265-47db-4665-a60d-d96005b2c0ad",
   "metadata": {},
   "source": [
    "No need to do this since fine tuning is already complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cf561ee-cfcf-4558-bbc2-0d35121652f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f6f5bf6-c0b0-410d-a193-91d8e706742f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[1;32m      2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      3\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilgpt2-finetuned-v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m---> 16\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mx_train\u001b[49m,\n\u001b[1;32m     17\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mx_val,\n\u001b[1;32m     18\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"distilgpt2-finetuned-v{ver}\",\n",
    "    save_total_limit=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=x_train,\n",
    "    eval_dataset=x_val,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e67a2399-c342-4994-922f-d93549040dc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_final_model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# DO NOT RUN THIS\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.save_model(f'v{ver}_final_model')  # DO NOT RUN THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012c750-d659-4dad-8959-1276081fea65",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0de6d9-cf0c-4ab4-ad64-4127ec1910fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "text_generator = pipeline('text-generation', tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "042cb98a-b037-4fe6-ab75-fc9ccfa48469",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "buffer = 8\n",
    "question = 'What are the moods evoked by the following song excerpt?'\n",
    "\n",
    "def process_lyrics(lyrics: str) -> list[str]:\n",
    "    extra_tokens = len(tokenizer(f'Q: {question}\\n\\nA: ')['input_ids'])\n",
    "    this_chunk_size = chunk_size - extra_tokens\n",
    "    all_tokens = tokenizer(lyrics)['input_ids']\n",
    "    chunks = [all_tokens[i:i + this_chunk_size] for i in range(0, len(all_tokens), this_chunk_size)]\n",
    "    chunks = [f'Q: {question}\\n{tokenizer.decode(i)}\\nA: ' for i in chunks]\n",
    "    chunks = tokenizer(chunks, padding=False, truncation=True, max_length=chunk_size + buffer)['input_ids']\n",
    "    return chunks  # Remove last element to avoid misaligned sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9512b8f8-d09b-48b3-8771-279936d788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LYRICS = \"\"\"\n",
    "Whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house (Hol' up)\n",
    "I said certified freak, seven days a week\n",
    "Wet-ass pussy, make that pullout game weak, woo (Ah)\n",
    "\n",
    "Yeah, yeah, yeah, yeah\n",
    "Yeah, you fuckin' with some wet-ass pussy\n",
    "Bring a bucket and a mop for this wet-ass pussy\n",
    "Give me everything you got for this wet-ass pussy\n",
    "\n",
    "Beat it up, nigga, catch a charge\n",
    "Extra large and extra hard\n",
    "Put this pussy right in your face\n",
    "Swipe your nose like a credit card\n",
    "Hop on top, I wanna ride\n",
    "I do a kegel while it's inside\n",
    "Spit in my mouth, look in my eyes\n",
    "This pussy is wet, come take a dive\n",
    "Tie me up like I'm surprised\n",
    "Let's roleplay, I'll wear a disguise\n",
    "I want you to park that big Mack truck right in this little garage\n",
    "Make it cream, make me scream\n",
    "Out in public, make a scene\n",
    "I don't cook, I don't clean\n",
    "But let me tell you how I got this ring (Ayy, ayy)\n",
    "\n",
    "Gobble me, swallow me, drip down the side of me (Yeah)\n",
    "Quick, jump out 'fore you let it get inside of me (Yeah)\n",
    "I tell him where to put it, never tell him where I'm 'bout to be (Huh)\n",
    "I'll run down on him 'fore I have a nigga runnin' me (Pow, pow, pow)\n",
    "Talk your shit, bite your lip (Yeah)\n",
    "Ask for a car while you ride that dick (While you ride that dick)\n",
    "You really ain't never gotta fuck him for a thang (Yeah)\n",
    "He already made his mind up 'fore he came (Ayy, ah)\n",
    "Now get your boots and your coat for this wet-ass pussy (Ah, ah, ah)\n",
    "He bought a phone just for pictures of this wet-ass pussy (Click, click, click)\n",
    "Paid my tuition just to kiss me on this wet-ass pussy (Mwah, mwah, mwah)\n",
    "Now make it rain if you wanna see some wet-ass pussy (Yeah, yeah)\n",
    "\n",
    "Look, I need a hard hitter, need a deep stroker\n",
    "Need a Henny drinker, need a weed smoker\n",
    "Not a garter snake, I need a king cobra\n",
    "With a hook in it, hope it lean over\n",
    "He got some money, then that's where I'm headed\n",
    "Pussy A1 just like his credit\n",
    "He got a beard, well, I'm tryna wet it\n",
    "I let him taste it, now he diabetic\n",
    "I don't wanna spit, I wanna gulp\n",
    "I wanna gag, I wanna choke\n",
    "I want you to touch that lil' dangly thing that swing in the back of my throat\n",
    "My head game is fire, punani Dasani\n",
    "It's goin' in dry and it's comin' out soggy\n",
    "I ride on that thing like the cops is behind me (Yeah, ah)\n",
    "I spit on his mic and now he tryna sign me, woo\n",
    "\n",
    "Your honor, I'm a freak bitch, handcuffs, leashes\n",
    "Switch my wig, make him feel like he cheatin'\n",
    "Put him on his knees, give him somethin' to believe in\n",
    "Never lost a fight, but I'm lookin' for a beatin' (Ah)\n",
    "In the food chain, I'm the one that eat ya\n",
    "If he ate my ass, he's a bottom-feeder\n",
    "Big D stand for big demeanor\n",
    "I could make ya bust before I ever meet ya\n",
    "If it don't hang, then he can't bang\n",
    "You can't hurt my feelings, but I like pain\n",
    "If he fuck me and ask \"Whose is it?\"\n",
    "When I ride the dick, I'ma spell my name, ah\n",
    "\n",
    "Yeah, yeah, yeah\n",
    "Yeah, you fuckin' with some wet-ass pussy\n",
    "Bring a bucket and a mop for this wet-ass pussy\n",
    "Give me everything you got for this wet-ass pussy\n",
    "Now from the top, make it drop, that's some wet-ass pussy\n",
    "Now get a bucket and a mop, that's some wet-ass pussy\n",
    "I'm talkin' wap, wap, wap, that's some wet-ass pussy\n",
    "Macaroni in a pot, that's some wet-ass pussy, huh\n",
    "\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "There's some whores in this house\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05caa612-19ca-4489-946e-846ea4e560e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_lyrics_chunks = process_lyrics(LYRICS)\n",
    "len(processed_lyrics_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f48245de-7592-4833-a260-02bd3074b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the moods evoked by the following song excerpt?\n",
      " pussy\n",
      "Give me everything you got for this wet-ass pussy\n",
      "\n",
      "Beat it up, nigga, catch a charge\n",
      "Extra large and extra hard\n",
      "Put this pussy right in your face\n",
      "Swipe your nose like a credit card\n",
      "Hop on top, I wanna ride\n",
      "I do a kegel while it's inside\n",
      "Spit in my mouth, look in my eyes\n",
      "This pussy is wet, come take a dive\n",
      "Tie me up like I'm surprised\n",
      "Let's roleplay, I'll wear a disguise\n",
      "\n",
      "A: iced, driving, energetic, gritty, energetic,\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(text_generator(tokenizer.decode(processed_lyrics_chunks[idx]), \n",
    "                     max_length=len(processed_lyrics_chunks[idx]) + 10)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4877b-d26b-4a91-8698-aa756584b19d",
   "metadata": {},
   "source": [
    "1. function to analyze an entire song\n",
    "    - collate tags from all excerpts\n",
    "    - rank tags\n",
    "    - select some number of best tags as output\n",
    "2. function to evaluate model's performance on a single song\n",
    "    - inputs: model's generated text, correct tags from dataset ground truth\n",
    "    - output: numerical score indicating how well the model performed (ideally 0-1)\n",
    "    - could factor in multiple runs per song?\n",
    "3. apply function to all songs in dataset and plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69d551a7-a430-4af4-8ec4-b1d64c2dcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST = [\n",
    "    'ive',\n",
    "    'ersatz',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c739f1e-f1b1-4b93-9add-e19f2b669e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['smooth', 'iced', 'trippy']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_TOKEN = tokenizer(tokenizer.pad_token)['input_ids'][0]\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "def check(word: str) -> bool:\n",
    "    if word == spell.correction(word) and word not in BLACKLIST:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_array(array):\n",
    "    tags_array = []\n",
    "    for i in array:\n",
    "        tags_array += i\n",
    "    return tags_array\n",
    "    \n",
    "def tags_for_excerpt(tokens: list) -> str:\n",
    "    # tokens = tokenizer(excerpt)['input_ids']\n",
    "    excerpt = tokenizer.decode(tokens)\n",
    "    output = text_generator(excerpt, \n",
    "                         max_length=len(tokens) + 10)[0]['generated_text']\n",
    "    response = output[output.rfind('A: ') + 3:]\n",
    "    response_tags = response.split(', ')\n",
    "    response_tags = [i.strip(', \\nÂ') for i in response_tags]\n",
    "    response_tags = list(filter(check, response_tags))\n",
    "    return response_tags\n",
    "\n",
    "import numpy as np\n",
    "def format_tags(tags):\n",
    "    unique_tags, counts = np.unique(tags, return_counts=True)\n",
    "    sorted_tags = unique_tags[np.argsort(counts)][::-1]\n",
    "    return list(sorted_tags[:3])\n",
    "\n",
    "def format_lyrics(lyrics):\n",
    "    lyrics_lst = lyrics.split(\"\\n\")\n",
    "    result = [[lyrics_lst[0], 1]]\n",
    "\n",
    "    for i in range(len(lyrics_lst) - 1):\n",
    "        if lyrics_lst[i] != lyrics_lst[i+1] or lyrics_lst[i+1] == '':\n",
    "            result.append([lyrics_lst[i+1], 1])\n",
    "        else:\n",
    "            result[-1][1] += 1\n",
    "\n",
    "    result2 = [i[0] for i in result]\n",
    "    for i in range(len(result)):\n",
    "        if result[i][1] > 1:\n",
    "            result2[i] += f\" (x{result[i][1]})\"\n",
    "    return '\\n'.join(result2)\n",
    "\n",
    "def gen_tags(lyrics: str) -> list[list[str]]:\n",
    "    lyrics = format_lyrics(lyrics)\n",
    "    chunks = process_lyrics(lyrics)\n",
    "    result = [tags_for_excerpt(i) for i in chunks]\n",
    "    \n",
    "    tags_array = flatten_array(result)\n",
    "    \n",
    "    return format_tags(tags_array)\n",
    "\n",
    "def lyrics_array(lyrics_arr):\n",
    "    return flatten_array(\n",
    "        list(\n",
    "            map(gen_tags, lyrics_arr)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "tags = lyrics_array([LYRICS])\n",
    "tags\n",
    "#print(format_lyrics(LYRICS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e5a62",
   "metadata": {},
   "source": [
    "Let's say we make a function song_analysis_pipeline(song_lyrics, num_tags_to_select).\n",
    "\n",
    "For each dataset element:\n",
    "\n",
    "- Lyrics\n",
    "- Correct tags\n",
    "\n",
    "Count correct tags, results = song_analysis_pipeline(Lyrics, len(correct_tags)).\n",
    "\n",
    "score = number of tags in results which are also in correct_tags / total number of correct tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b830036-6b12-4677-b2bb-3859eac480f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
